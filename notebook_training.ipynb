{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55a22c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# TRAINING CONFIG\n",
    "# =========================\n",
    "CONFIG = {\n",
    "    \"data\": {\n",
    "        \"csv_path\":      r\"C:\\\\Users\\\\rcper\\Desktop\\SGN_NILM2\\\\refit_data\\\\CLEAN_House2.csv\",  \n",
    "        \"appliance_col\": \"Appliance1\",                    \n",
    "        \"max_rows\":      750_000,\n",
    "        \"resample_rule\": \"30s\",\n",
    "        \"train_split\":   0.70,  # 70% train, 15% val, 15% test\n",
    "        \"val_split\":     0.85,\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"backbone_kind\": \"tcn\",  \n",
    "        \"win_len\":       256,\n",
    "        \"stride\":        32,\n",
    "    },\n",
    "    \"optim\": {\n",
    "        \"batch_size\": 32,\n",
    "        \"lr\":         1e-3,\n",
    "        \"patience\":   10,\n",
    "        \"min_delta\":  0.0,\n",
    "        \"use_scheduler\": False,\n",
    "    },\n",
    "    \"staged_training\": {\n",
    "        \"epochs_reg\":   5,   # regressor pretrain\n",
    "        \"epochs_cls\":   3,   # classifier pretrain\n",
    "        \"epochs_joint\": 60,  # joint finetune\n",
    "        \"on_sample_prob_reg\": 0.7,  # oversampling ONLY for reg batches\n",
    "    },\n",
    "    \"loss\": {\n",
    "        \"delta_watts\":     50.0,  # Huber delta in Watts\n",
    "        \"alpha_on\":        1.0,   # ON regression on gated power\n",
    "        \"alpha_reg_raw\":   1.0,   # ON regression on raw reg head\n",
    "        \"alpha_off\":       0.02,  # tiny leak penalty when OFF\n",
    "        \"beta_cls\":        1.5,   # BCE weight\n",
    "        \"focal_gamma\":     2.0,   # focal BCE focusing\n",
    "        \"pos_weight_cap\":  8.0,   # cap for neg/pos weighting\n",
    "    },\n",
    "    \"checkpoint\": {\n",
    "        \"ckpt_path\": \"sgn_best.pt\"\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b011475d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# IMPORTS\n",
    "# =========================\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from dataset import Seq2PointWindows\n",
    "from training import main_train_staged\n",
    "from loss import delta_from_watts\n",
    "from inference import (\n",
    "    infer_seq2point_timeline_all,\n",
    "    infer_seq2point_timeline_all_with_hard,\n",
    "    tune_hysteresis_for_mae,\n",
    "    smape,\n",
    ")\n",
    "from sgnNet import SGN\n",
    "from refit_dataloader import load_house_csv\n",
    "\n",
    "# plotting utils (decoupled)\n",
    "from plot import plot_training_curves, plot_reg_vs_true, plot_soft, plot_hard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc16ef2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 750000 samples for Appliance1\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# LOAD DATA\n",
    "# =========================\n",
    "\n",
    "mains_all, target_all, ts_all = load_house_csv(\n",
    "    CONFIG[\"data\"][\"csv_path\"],\n",
    "    appliance_col=CONFIG[\"data\"][\"appliance_col\"],\n",
    "    max_rows=CONFIG[\"data\"][\"max_rows\"],\n",
    "    resample_rule=CONFIG[\"data\"][\"resample_rule\"],\n",
    ")\n",
    "print(f\"Loaded {len(mains_all)} samples for {CONFIG['data']['appliance_col']}\")\n",
    "\n",
    "# Split\n",
    "n = len(mains_all)\n",
    "train_end = int(CONFIG[\"data\"][\"train_split\"] * n)\n",
    "val_end   = int(CONFIG[\"data\"][\"val_split\"] * n)\n",
    "\n",
    "mains_train, target_train = mains_all[:train_end], target_all[:train_end]\n",
    "mains_val,   target_val   = mains_all[train_end:val_end], target_all[train_end:val_end]\n",
    "mains_test,  target_test  = mains_all[val_end:], target_all[val_end:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be61c083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ON rate ~ 0.1246 → pos_weight=7.03, delta(huber)=0.53763 (scaled)\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# PREP DATA STATS & LOSS PARAMS\n",
    "# =========================\n",
    "WIN_LEN  = CONFIG[\"model\"][\"win_len\"]\n",
    "STRIDE   = CONFIG[\"model\"][\"stride\"]\n",
    "\n",
    "# Build small datasets JUST to compute scaling/imbalance\n",
    "train_ds = Seq2PointWindows(mains_train, target_train, win_len=WIN_LEN, stride=STRIDE, train=True)\n",
    "val_ds   = Seq2PointWindows(mains_val,   target_val,   win_len=WIN_LEN, stride=STRIDE, train=False)\n",
    "\n",
    "# Huber delta in scaled units\n",
    "delta = delta_from_watts(CONFIG[\"loss\"][\"delta_watts\"], train_ds.target_scale)\n",
    "\n",
    "# Class imbalance → pos_weight\n",
    "pos_rate = float(train_ds.onoff.mean() + 1e-9)\n",
    "neg_rate = 1.0 - pos_rate\n",
    "pos_weight = min(neg_rate / pos_rate, CONFIG[\"loss\"][\"pos_weight_cap\"])\n",
    "print(f\"ON rate ~ {pos_rate:.4f} → pos_weight={pos_weight:.2f}, delta(huber)={delta:.5f} (scaled)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b471c85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[REG] Epoch 001 | Train 0.0904 | ValLoss 1.7913 | ValMAE 48.87\n",
      "[REG] Epoch 002 | Train 0.0566 | ValLoss 1.5800 | ValMAE 47.32\n",
      "[REG] Epoch 003 | Train 0.0527 | ValLoss 2.1673 | ValMAE 50.26\n",
      "[REG] Epoch 004 | Train 0.0505 | ValLoss 1.7905 | ValMAE 45.66\n",
      "[REG] Epoch 005 | Train 0.0469 | ValLoss 1.9570 | ValMAE 45.60\n",
      "[CLS] Epoch 001 | Train 0.1383 | ValLoss 0.3824 | ValMAE 32.16\n",
      "[CLS] Epoch 002 | Train 0.0718 | ValLoss 0.3512 | ValMAE 27.28\n",
      "[CLS] Epoch 003 | Train 0.0638 | ValLoss 0.3346 | ValMAE 22.18\n",
      "[JOINT] Epoch 001 | Train 0.1558 | ValLoss 0.3353 | ValMAE 35.83\n",
      "[JOINT] Epoch 002 | Train 0.1485 | ValLoss 0.3167 | ValMAE 33.58\n",
      "[JOINT] Epoch 003 | Train 0.1468 | ValLoss 0.3205 | ValMAE 28.97\n",
      "[JOINT] Epoch 004 | Train 0.1380 | ValLoss 0.2990 | ValMAE 27.28\n",
      "[JOINT] Epoch 005 | Train 0.1367 | ValLoss 0.3293 | ValMAE 27.16\n",
      "[JOINT] Epoch 006 | Train 0.1376 | ValLoss 0.3042 | ValMAE 27.93\n",
      "[JOINT] Epoch 007 | Train 0.1326 | ValLoss 0.2984 | ValMAE 29.95\n",
      "[JOINT] Epoch 008 | Train 0.1239 | ValLoss 0.3132 | ValMAE 31.57\n",
      "[JOINT] Epoch 009 | Train 0.1331 | ValLoss 0.3279 | ValMAE 28.73\n",
      "[JOINT] Epoch 010 | Train 0.1257 | ValLoss 0.2783 | ValMAE 25.31\n",
      "[JOINT] Epoch 011 | Train 0.1264 | ValLoss 0.2865 | ValMAE 29.12\n",
      "[JOINT] Epoch 012 | Train 0.1208 | ValLoss 0.2712 | ValMAE 24.28\n",
      "[JOINT] Epoch 013 | Train 0.1163 | ValLoss 0.2868 | ValMAE 28.49\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# TRAIN (STAGED)\n",
    "# =========================\n",
    "results = main_train_staged(\n",
    "    mains_train, target_train,\n",
    "    mains_val,   target_val,\n",
    "    win_len=CONFIG[\"model\"][\"win_len\"],\n",
    "    stride=CONFIG[\"model\"][\"stride\"],\n",
    "    batch_size=CONFIG[\"optim\"][\"batch_size\"],\n",
    "    lr=CONFIG[\"optim\"][\"lr\"],\n",
    "    epochs_reg=CONFIG[\"staged_training\"][\"epochs_reg\"],\n",
    "    epochs_cls=CONFIG[\"staged_training\"][\"epochs_cls\"],\n",
    "    epochs_joint=CONFIG[\"staged_training\"][\"epochs_joint\"],\n",
    "    on_sample_prob_reg=CONFIG[\"staged_training\"][\"on_sample_prob_reg\"],\n",
    "    kind=CONFIG[\"model\"][\"backbone_kind\"],\n",
    "    patience=CONFIG[\"optim\"][\"patience\"],\n",
    "    min_delta=CONFIG[\"optim\"][\"min_delta\"],\n",
    "    ckpt_path=CONFIG[\"checkpoint\"][\"ckpt_path\"],\n",
    "    delta_huber=delta,\n",
    "    focal_gamma=CONFIG[\"loss\"][\"focal_gamma\"],\n",
    "    pos_weight=pos_weight,\n",
    "    alpha_on=CONFIG[\"loss\"][\"alpha_on\"],\n",
    "    alpha_reg_raw=CONFIG[\"loss\"][\"alpha_reg_raw\"],\n",
    "    alpha_off=CONFIG[\"loss\"][\"alpha_off\"],\n",
    "    beta_cls=CONFIG[\"loss\"][\"beta_cls\"],\n",
    "    use_scheduler=CONFIG[\"optim\"][\"use_scheduler\"],\n",
    "    plot=False,  # plotting handled later via plot.py\n",
    ")\n",
    "\n",
    "print(\"Best Val MAE (W):\", results[\"best_val_mae\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61910c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# LOAD BEST MODEL & RUN INFERENCE\n",
    "# =========================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ckpt = torch.load(CONFIG[\"checkpoint\"][\"ckpt_path\"], map_location=device)\n",
    "\n",
    "model = SGN(in_ch=1, hid=64, kind=CONFIG[\"model\"][\"backbone_kind\"], out_len=1).to(device)\n",
    "model.load_state_dict(ckpt[\"model\"])\n",
    "stats = ckpt[\"stats\"]\n",
    "\n",
    "gate_tau = stats.get(\"gate_tau\", 0.75) if isinstance(stats, dict) else 0.75\n",
    "\n",
    "# Validation inference for hysteresis tuning\n",
    "pow_val_soft, reg_val_w, prob_val = infer_seq2point_timeline_all(model, mains_val, stats, device, gate_tau=gate_tau)\n",
    "y_val = target_val\n",
    "t_on, t_off, min_hold, best_val_mae = tune_hysteresis_for_mae(reg_val_w, prob_val, y_val, gate_floor=0.0)\n",
    "print(f\"[HYSTERESIS][VAL] best → t_on={t_on:.2f}, t_off={t_off:.2f}, min_hold={min_hold} | MAE={best_val_mae:.2f} W\")\n",
    "\n",
    "# Test inference (soft + hard)\n",
    "power_soft_w, reg_w, prob, gate_hard, power_hard_w = infer_seq2point_timeline_all_with_hard(\n",
    "    model, mains_test, stats, device,\n",
    "    gate_tau=gate_tau,\n",
    "    t_on=t_on, t_off=t_off, min_hold=min_hold,\n",
    "    gate_floor=0.0\n",
    ")\n",
    "y_true = target_test\n",
    "\n",
    "# Metrics\n",
    "mae_soft = float(np.mean(np.abs(power_soft_w - y_true)))\n",
    "mae_hard = float(np.mean(np.abs(power_hard_w - y_true)))\n",
    "energy_true = float(y_true.sum())\n",
    "sae_soft = float(abs(power_soft_w.sum() - energy_true) / (energy_true + 1e-6))\n",
    "sae_hard = float(abs(power_hard_w.sum() - energy_true) / (energy_true + 1e-6))\n",
    "print(f\"[TEST][SOFT] MAE={mae_soft:.2f} W | SAE={sae_soft:.4f} | sMAPE={smape(y_true, power_soft_w):.2f}%\")\n",
    "print(f\"[TEST][HARD] MAE={mae_hard:.2f} W | SAE={sae_hard:.4f} | sMAPE={smape(y_true, power_hard_w):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facd7598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# PLOTS \n",
    "# =========================\n",
    "PLOT_CFG = {\n",
    "    \"enable_training_curve\": True,\n",
    "    \"show_regression\": True,\n",
    "    \"show_soft\": True,\n",
    "    \"show_hard\": True,\n",
    "    \"test_plot_len\": 80_000,\n",
    "    \"on_threshold_for_plot\": 15.0,  # for binary true_on curve in hard plot\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "N = min(PLOT_CFG[\"test_plot_len\"], len(y_true))\n",
    "\n",
    "plot_training_curves(results, enable=PLOT_CFG[\"enable_training_curve\"])\n",
    "plot_reg_vs_true(y_true, reg_w, N=N, show=PLOT_CFG[\"show_regression\"])\n",
    "plot_soft(y_true, power_soft_w, N=N, show=PLOT_CFG[\"show_soft\"])\n",
    "plot_hard(y_true, power_hard_w, gate_hard,\n",
    "          on_threshold=PLOT_CFG[\"on_threshold_for_plot\"],\n",
    "          N=N, show=PLOT_CFG[\"show_hard\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sgnCuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
